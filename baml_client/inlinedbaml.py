# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n//Example Google AI client (uncomment to use)\nclient<llm> CustomGemini {\n  provider google-ai\n  options {\n    model \"gemini-1.0-pro\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> MyFreeClient {\n  provider openai-generic\n  options {\n    base_url \"https://api.groq.com/openai/v1\"\n    api_key env.GROQ_API_KEY\n    model \"llama-3.3-70b-versatile\"\n  }\n}\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.218.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "prompts.baml": "class Project {\n  name string\n  description string[]\n  tech_stack string[] \n  role string\n  complexity int\n}\n\nenum Intent {\n  ProbeDepth\n  Clarify\n  Challenge\n  MoveOn\n  SwitchProject\n  WrapUp\n}\n\nenum InterviewStage {\n  Intro\n  DeepDive\n  FollowUp\n  WrapUp\n}\n\nclass AnswerAnalysis {\n  clarity int\n  correctness int\n  depth int\n  review string\n\n}\nclass ProjectPastContext {\n  weak_areas string[]\n  strong_areas string[]\n  unanswered_concepts string[]\n  coverage_score float\n\n}\n\nclass ProjectState {\n  name string\n  description string[]\n  claimed_stack string[]\n  complexity int\n  question_ids map<string, string>\n  followup_count map<string, int>\n  parent_questions map<string, string>\n  per_question_answer_analysis map<string, AnswerAnalysis>?\n  overall_analysis ProjectPastContext\n}\n\nclass InterviewDecision {\n  intent Intent\n  urgency float\n  confidence float\n  rationale string\n}\n\nclass InterviewState {\n  stage InterviewStage\n  turn_index int\n  max_turns int\n  max_followups_per_question int\n  max_questions_per_project int\n  projects_done map<string, bool>\n  active_project_id string | null\n  active_question_id string | null\n  projects map<string, ProjectState>\n  decision InterviewDecision\n  last_answer string | null\n}\n\nclass QuestionResponse {\n  question string\n  question_id string\n  parent_question_id string\n}\n\nclass AnalysisResponse {\n  analysis AnswerAnalysis\n  decision InterviewDecision\n  pastContext ProjectPastContext\n\n}\n\n\n\nfunction ExtractProjects(resume_text: string) -> Project[]{\n\n    client MyFreeClient \n    prompt #\"\n    {{ _.role('system') }}\n    Extract projects from the input. For each project, follow these specific formatting rules for the 'description' field:\n    \n    1. The FIRST element must be a high-level summary of the project's purpose.\n    2. Subsequent elements must be specific technical details, such as architecture choices, performance wins, or specific algorithms used\n    \n    GUIDELINES:\n    1. For 'tech_stack', extract specific tools/languages. If none are mentioned, return null.\n    2. For 'complexity', rate the project from 1-10 based on technical depth and scale.\n    3. For 'role', identify the specific contribution (e.g., 'Lead Developer', 'Contributor').\n\n    include internship projects as well.\n\n    {{ ctx.output_format }}\n\n    {{ _.role('user') }}\n    Analyze the following content and extract the projects:\n    ---\n    {{ resume_text }}\n    ---\n\n    Before providing the JSON, briefly reason about why you assigned the specific complexity score for each project.\n  \"#\n\n}\n\n\nfunction GenerateQuestion(\n  state: InterviewState,\n  intent: Intent,\n  urgency: float\n) -> QuestionResponse {\n\n  client MyFreeClient\n\n  prompt #\"\n  {# ================= SYSTEM PERSONA ================= #}\n  You are a senior technical interviewer having a natural technical conversation.\n  Each question should feel like a continuation of what was just discussed,\n  not a fresh or disconnected prompt.\n\n  Ask ONE precise, high-signal question per turn.\n\n  {% set project = state.projects[state.active_project_id] %}\n  Active Project: {{ project.name }}\n  Stack: {{ project.claimed_stack | join(\", \") }}\n  Complexity: {{ project.complexity }}/10\n\n  {# ================= STAGE: INTRO ================= #}\n  {% if state.stage == \"INTRO\" %}\n    TASK:\n    Ask ONE open-ended, conversational question that invites the candidate to:\n    - Explain what the project does\n    - Describe the problem it solves\n    - Clarify their role\n\n    Style:\n    - Natural and human (as in a real interview)\n    - Encouraging, not interrogative\n\n    Rules:\n    - No implementation details\n    - No challenges or edge cases\n\n    {{ ctx.output_format }}\n\n  {% endif %}\n\n  {# ================= CONTEXT: PAST QUESTIONS ================= #}\n  {% if project.question_ids | length > 0 %}\n    {% set total_q = project.question_ids | length %}\n    {% set max_q = state.max_questions_per_project %}\n    \n    Questions: {{ total_q }}/{{ max_q }}\n    Coverage: {{ project.overall_analysis.coverage_score * 100 | round }}%\n    \n    {% if project.unanswered_concepts %}\n    Untested: \n    {%- for concept in project.unanswered_concepts -%}\n        {{ concept }}{% if not loop.last %}, {% endif %}\n    {%- endfor -%}\n    {% endif %}\n    \n    {% if project.weak_areas %}\n    Weak Areas: \n    {%- for area in project.weak_areas -%}\n        {{ area }}{% if not loop.last %}, {% endif %}\n    {%- endfor -%}\n    {% endif %}\n\n    {% if project.strong_areas %}\n    Strong Areas: \n    {%- for area in project.strong_areas -%}\n        {{ area }}{% if not loop.last %}, {% endif %}\n    {%- endfor -%}\n    {% endif %}\n\n    {% if total_q >= 3 %}\n      Recent Questions (last 3):\n      {% for  q in project.question_ids | reverse | slice(3) %}\n      - {{ q.value }}\n      {% endfor %}\n    {% endif %}\n\n  {% else %}\n    No questions asked yet.\n    Coverage: 0%\n    All concepts untested: {{ project.claimed_stack | join(\", \") }}\n    ASK TO GIVE A HIGH-LEVEL OVERVIEW OF THE PROJECT FIRST.\n\n  {% endif %}\n\n\n  {# ================= INTERVIEWER DECISION ================= #}\n\n  RULE:\n  - Do NOT repeat or paraphrase any of the questions above.\n  - Each new question must advance the discussion into a new angle or deeper layer.\n\n  {# ================= FOLLOW-UP MODE ================= #}\n  {% if intent == Intent.FollowUp and state.active_question_id %}\n    {% set qid = state.active_question_id %}\n    {% set analysis = project.per_question_answer_analysis[qid] %}\n\n    Last Question Asked:\n    {{ project.question_ids[qid] }}\n\n    Answer Analysis:\n    - Strengths: {{ analysis.strengths }}\n    - Gaps: {{ analysis.gaps }}\n    - Weaknesses: {{ analysis.weaknesses }}\n    - Confidence: {{ analysis.confidence }}\n\n    TASK:\n    Ask ONE conversational follow-up that:\n    - Naturally references what the candidate just said\n    - Zooms in on a specific gap or weak assumption\n    - Feels like “let’s dig a bit deeper here” rather than a new topic\n\n    Style Rules:\n    - Phrase it as a continuation (e.g., “You mentioned…”, “Earlier you said…”)\n    - Avoid reset phrases like “Explain” or “Describe”\n\n    Constraints:\n    - No multi-part questions\n    - Narrow aggressively if urgency > 0.7\n\n    {{ ctx.output_format }}\n    STOP.\n  {% endif %}\n\n  {# ================= DEFAULT DEEPDIVE ================= #}\n  TASK:\n  Ask ONE conversational, implementation-rooted question based on:\n  {{ project.claimed_stack | join(\"/\") }}\n\n  Intent: {{ intent }}\n  Urgency: {{ urgency }}\n\n  Conversational Guidelines:\n  - Reference earlier discussion implicitly or explicitly\n  - Prefer continuation phrases:\n      • “When you were building…”\n      • “Earlier you mentioned…”\n      • “That choice makes sense — how did you…”\n  - Focus on trade-offs, constraints, or real failure cases, backtesting their decisions\n  - Avoid sounding like a checklist or exam question\n\n  Hard Constraints:\n  - No textbook definitions\n  - No multi-part questions\n\n  {{ ctx.output_format }}\n\n  \"#\n}\n\n\nfunction AnalyzeAnswer(question: string, answer: string, state: InterviewState) -> AnalysisResponse{\n    client MyFreeClient\n    prompt #\"\n    {{ _.role('system') }}\n    You are a meticulous technical interviewer analyzing candidate answers.\n\n    TASK 1 - Evaluate Answer:\n    1. Clarity (1-10): How clearly explained?\n    2. Correctness (1-10): Technically sound?\n    3. Depth (1-10): Trade-offs, alternatives, constraints covered?\n    \n    Provide:\n    - Concise review (strengths/weaknesses)\n    - Uncovered gaps or misconceptions from THIS answer\n\n    TASK 2 - Decide Next Action:\n    - **ProbeDepth**: Good answer, needs deeper implementation details\n    - **Clarify**: Unclear, ambiguous, needs precision\n    - **Challenge**: Incorrect, inconsistent, or needs validation\n    - **MoveOn**: Satisfactory and complete, new aspect needed\n    - **SwitchProject**: Project sufficiently covered\n    - **WrapUp**: Conclude interview\n\n    TASK 3 - Update Project Context:\n    Based on ALL answers so far (including this one):\n    - **weak_areas**: Topics/concepts where candidate struggled or showed gaps\n    - **strong_areas**: Topics/concepts where candidate demonstrated solid understanding\n    - **unanswered_concepts**: Technologies from claimed stack NOT yet tested/discussed\n    - **coverage_score** (0.0-1.0): % of claimed tech stack adequately covered\n\n    {{ ctx.output_format }}\n\n    {{ _.role('user') }}\n\n    {% set project = state.projects[state.active_project_id] %}\n    {# Initialize the variable #}\n    {% set total_q = 0 %}\n    {% for id in project.question_ids %}\n      {# Incrementing logic depends on your BAML runtime; usually, \n        you just iterate to display. If you need the number in the prompt: #}\n      {% if loop.last %}{% set total_q = loop.index %}{% endif %}\n    {% endfor %}\n\nTotal number of questions: {{ total_q }}\n\nTotal Questions: {{ total_q }}\n\n    {% set max_q = state.max_questions_per_project %}\n    {% set global_urgency = state.turn_index / state.max_turns %}\n\n    Covereage: {{ (project.overall_analysis.coverage_score * 100) | round }}%\n    **Budget Status:**\n    Turns: {{ state.turn_index }}/{{ state.max_turns }} ({{ (global_urgency * 100) | round }}% used)\n    Questions this project: {{ total_q }}/{{ max_q }}\n    {% if state.active_question_id %}\n    {% set current_root = project.parent_questions.get(state.active_question_id, state.active_question_id) %}\n    Followups on current thread: {{ project.followup_count.get(current_root, 0) }}/{{ state.max_followups_per_question }}\n    {% endif %}\n\n    **Decision Guidance:**\n    {% if total_q >= max_q * 0.8 %}\n      Question budget nearly exhausted ({{ total_q }}/{{ max_q }}) - PREFER MoveOn over followups\n    {% endif %}\n    {% if project.coverage_score >= 0.75 %}\n      Coverage satisfactory ({{ (project.coverage_score * 100) | round }}%) - CONSIDER SwitchProject, don't exhaust question budget\n    {% endif %}\n    {% if global_urgency >= 0.8 %}\n      Global time critical ({{ (global_urgency * 100) | round }}% used) - AVOID deep followups, prioritize breadth\n    {% endif %}\n    {% if total_q >= max_q %}\n      Question budget exhausted - MUST use MoveOn or SwitchProject\n    {% endif %}\n\n    **Project: {{ project.name }}**\n    Claimed Stack: {{ project.claimed_stack | join(\", \") }}\n    Current Coverage: {{ (project.coverage_score * 100) | round }}%\n    {% if project.weak_areas | length > 0 %}Current Weak: {{ project.weak_areas | join(\", \") }}{% endif %}\n    {% if project.strong_areas | length > 0 %}Current Strong: {{ project.strong_areas | join(\", \") }}{% endif %}\n    {% if project.unanswered_concepts | length > 0 %}Currently Untested: {{ project.unanswered_concepts | join(\", \") }}{% endif %}\n\n    {% if project.per_question_answer_analysis | length > 0 %}\n    **Accumulated Gaps from Previous Answers:**\n    {% set all_gaps = [] %}\n    {% for var in project.per_question_answer_analysis %}\n    {% set _ = all_gaps.extend(var.value.uncovered_gaps) %}\n    {% endfor %}\n    {% if all_gaps | length > 0 %}{{ all_gaps | unique | join(\", \") }}{% endif %}\n    {% endif %}\n\n    **Current Question:**\n    {{ question }}\n\n    **Candidate's Answer:**\n    {{ answer }}\n\n    ---\n    Now provide your complete analysis with all three tasks: answer evaluation, decision, and updated project context.\n    \"#\n}\n\nfunction FinalAnalysis(state: InterviewState) -> string {\n    client MyFreeClient\n    prompt #\"\n    {{ _.role('system') }}\n    You are a senior technical interviewer providing a comprehensive final evaluation.\n\n    TASK:\n    Provide a structured final report with:\n    1. Overall Performance Summary (strengths, weaknesses, consistency)\n    2. Technical Depth Assessment (per technology/concept)\n    3. Red Flags & Green Flags\n    4. Hiring Recommendation (Strong Hire / Hire / No Hire / Strong No Hire)\n    5. Suggested Level (Junior / Mid / Senior / Staff)\n\n    {{ ctx.output_format }}\n\n    {{ _.role('user') }}\n\n    **Interview Summary:**\n    Total Turns: {{ state.turn_index }}/{{ state.max_turns }}\n    {% set completed_count = 0 %}\n    {% for proj_id in state.projects_done.keys() %}\n    {% if state.projects_done[proj_id] %}{% set completed_count = completed_count + 1 %}{% endif %}\n    {% endfor %}\n    Projects Covered: {{ completed_count }}/{{ state.projects.keys() | length }}\n\n    {% for proj_id in state.projects.keys() %}\n    {% set project = state.projects[proj_id] %}\n    ---\n    **Project {{ loop.index }}: {{ project.name }}**\n    Complexity: {{ project.complexity }}/10\n    Claimed Stack: {{ project.claimed_stack | join(\", \") }}\n    \n    Coverage: {{ (project.coverage_score * 100) | round }}%\n    Questions Asked: {{ project.question_ids.keys() | length }}\n    \n    {% if project.strong_areas | length > 0 %}\n    Strong Areas: {{ project.strong_areas | join(\", \") }}\n    {% endif %}\n    \n    {% if project.weak_areas | length > 0 %}\n    Weak Areas: {{ project.weak_areas | join(\", \") }}\n    {% endif %}\n    \n    {% if project.unanswered_concepts | length > 0 %}\n    Untested: {{ project.unanswered_concepts | join(\", \") }}\n    {% endif %}\n\n    **Answer Quality Distribution:**\n    {% for qid in project.per_question_answer_analysis.keys() %}\n    {% set analysis = project.per_question_answer_analysis[qid] %}\n    Q{{ loop.index }}: Clarity={{ analysis.clarity }}/10, Correctness={{ analysis.correctness }}/10, Depth={{ analysis.depth }}/10\n    Review: {{ analysis.review }}\n    {% if analysis.uncovered_gaps | length > 0 %}\n      Gaps: {{ analysis.uncovered_gaps | join(\", \") }}\n    {% endif %}\n    {% endfor %}\n\n    {% endfor %}\n\n    **Cross-Project Patterns:**\n    {% set all_weak = [] %}\n    {% set all_strong = [] %}\n    {% for proj_id in state.projects.keys() %}\n    {% set project = state.projects[proj_id] %}\n    {% for weak in project.weak_areas %}\n    {% set _ = all_weak.append(weak) %}\n    {% endfor %}\n    {% for strong in project.strong_areas %}\n    {% set _ = all_strong.append(strong) %}\n    {% endfor %}\n    {% endfor %}\n    \n    Recurring Weaknesses: {{ all_weak | unique | join(\", \") if all_weak | length > 0 else \"None\" }}\n    Consistent Strengths: {{ all_strong | unique | join(\", \") if all_strong | length > 0 else \"None\" }}\n    \"#\n}\n\n// test TestName {\n//   functions [GenerateQuestion]\n//   args {\n//     state {\n//         stage Intro\n//         turn_index 1\n//         max_turns 20\n//         max_followups_per_question 3\n//         max_questions_per_project 6\n//         projects_done {\n//         \"a_string\" false\n//       }\n//         active_project_id \"a_string\"\n//         active_question_id null\n//         projects {\n//         \"a_string\" {\n//             name #\"\n//             hello world\n//           \"#\n//             description [\n//             #\"\n//               hello world\n//             \"#,\n//             #\"\n//               hello world\n//             \"#\n//           ]\n//             claimed_stack [\n//             #\"\n//               hello world\n//             \"#,\n//             #\"\n//               hello world\n//             \"#\n//           ]\n//             complexity 123\n//             question_ids null\n//             followup_count null\n//             parent_questions null\n//             per_question_answer_analysis null\n//             overall_analysis null\n//         }\n//       }\n//         decision null\n//     }\n//     intent ProbeDepth\n//     urgency 0.5\n//   }\n// }\n\ntest TestName {\n  functions [GenerateQuestion]\n  args {\n    state {\n      stage \"Intro\"\n      turn_index 1\n      max_turns 20\n      max_followups_per_question 3\n      max_questions_per_project 6\n      projects_done {\n        \"project_0\" false\n        \"project_1\" false\n        \"project_2\" false\n        \"project_3\" false\n      }\n      active_project_id \"project_0\"\n      active_question_id \"probe_lstm_overfitting\"\n      projects {\n        \"project_0\" {\n          name \"CDS Index Trading via Merton-Enhanced LSTM Models\"\n          description [\n            \"Developed and implemented a Merton-LSTM model for forecasting CDS index spreads\",\n            \"Used machine learning techniques like LSTM and Merton's model for credit risk assessment\",\n            \"Demonstrated superior profitability and risk management compared to baseline models\"\n          ]\n          claimed_stack [\"Python\", \"Machine Learning\", \"LSTM\"]\n          complexity 9\n          question_ids {\n            \"probe_lstm_overfitting\" \"How did you handle overfitting in your Merton-LSTM model implementation, specifically with regards to the LSTM component and the dataset used for training the CDS index spread forecasts?\"\n          }\n          followup_count {\n            \"None\" 1\n          }\n          parent_questions {\n            \"probe_lstm_overfitting\" \"None\"\n          }\n          per_question_answer_analysis {}\n          overall_analysis {\n            weak_areas []\n            strong_areas []\n            unanswered_concepts [\"Python\", \"Machine Learning\", \"Data Structures\"]\n            coverage_score 0.0\n          }\n        }\n        \"project_1\" {\n          name \"Machine Learning Intern, NRSC ISRO\"\n          description [\n            \"Developed a high-performance LULC classification model for Delhi\",\n            \"Used Sentinel 2 L2A imagery and achieved 88% accuracy\"\n          ]\n          claimed_stack [\"Python\", \"Machine Learning\", \"Data Structures\"]\n          complexity 8\n          question_ids {}\n          followup_count {}\n          parent_questions {}\n          per_question_answer_analysis {}\n          overall_analysis {\n            weak_areas []\n            strong_areas []\n            unanswered_concepts [\"Python\", \"Machine Learning\", \"Data Structures\"]\n            coverage_score 0.0\n          }\n        }\n      }\n      decision {\n        intent \"ProbeDepth\"\n        urgency 0.3\n        confidence 0.6\n        rationale \"Initial probing\"\n      }\n      last_answer \"yo\"\n    }\n    intent ProbeDepth\n    urgency 0.5\n\n  }\n}\n\ntest TestName {\n  functions [AnalyzeAnswer]\n  args {\n    question #\"\n      hello world\n    \"#\n    answer #\"\n      hello world\n    \"#\n    state {\n        stage Intro\n        turn_index 123\n        max_turns 123\n        max_followups_per_question 123\n        max_questions_per_project 123\n        projects_done {\n        \"a_string\" true\n      }\n        active_project_id null\n        active_question_id null\n        projects {\n        \"a_string\" {\n            name #\"\n            hello world\n          \"#\n            description [\n            #\"\n              hello world\n            \"#,\n            #\"\n              hello world\n            \"#\n          ]\n            claimed_stack [\n            #\"\n              hello world\n            \"#,\n            #\"\n              hello world\n            \"#\n          ]\n            complexity 123\n            question_ids {\n            \"a_string\" #\"\n              hello world\n            \"#\n          }\n            followup_count {\n            \"a_string\" 123\n          }\n            parent_questions {\n            \"a_string\" #\"\n              hello world\n            \"#\n          }\n            per_question_answer_analysis null\n            overall_analysis {\n              weak_areas [\n              #\"\n                hello world\n              \"#,\n              #\"\n                hello world\n              \"#\n            ]\n              strong_areas [\n              #\"\n                hello world\n              \"#,\n              #\"\n                hello world\n              \"#\n            ]\n              unanswered_concepts [\n              #\"\n                hello world\n              \"#,\n              #\"\n                hello world\n              \"#\n            ]\n              coverage_score 0.5\n          }\n        }\n      }\n        decision {\n          intent ProbeDepth\n          urgency 0.5\n          confidence 0.5\n          rationale #\"\n          hello world\n        \"#\n      }\n        last_answer null\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return _file_map